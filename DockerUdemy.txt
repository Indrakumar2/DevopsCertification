Docker Intro:
There are three major things in Docker which made this tool a whole evolution in software development.

The Docker Image, Docker Registry and Docker Container.

These three components runs together like bread and butter which made the possibility of Build, Ship and Run anywhere.

The Docker image or the Container image:
(Universal app packaging)
There were many package managers that were brrn used in software packaging but some them were limited to the capabilities.
It resulted that a software packaging manager which has a feature of Cross OS, Cross Platform and application language agnostic,
means it will run everywhere, and it runs on anything, as long is running linux or windows.

DockerFile:
A Dockerfile is a set of instructions to make a container image. The Docker image specification was so popular it's now a standard,
Known as OCR image standard.

Every Docker file starts with FROM instruction, it can be start with someone else's image. 
we can also have many images from many FROM's.
Eg: 
FROM pyton           ------>python bins+libs
RUN pip install flask------> adds flask
WORKDIR /app----> meta data change in the filesystem. 
COPY .. ----> this command copies the source code from the host we're building into its own layer stacked on top
              of the others        
CMD python app.py   ------->

The docker conists of layers and with the capital letters called stanza. The docker process it from top down, will create layers.
The layers will be moved around the servers as tarballs and inside those layers are files, directories and file permissions, and 
sometimes metadata.

According to the example , docker finds the python image that includes binaries & Libraries.

This way the an image is build using Docker Build command.

THE DOCKER REGISTRY:
It is for application distribution.

Every image has unique SHA hash.

DOCKER CONTAINER RUN:

When we create a dockerfile and build the image we can run a container and this running container is known as a NAMESPACE(This is an Linux Feature in which
it prevents the application running in the container from seeing the rest of the operating system/ for Windows its diffrent Feature.) 

It gets it's own blank file system and it will includes only the files that were in that image being built.

It will gets its own IPAddress,ProcessList and Virtual NIC.

When we do the Docker run command , it the image not present locally, then the Docker downloads the image automatically.

MAJOR LINUX FEARTURES USED BY DOCKER:

NAMESPACES-, CGROUPS, VETH(virtual Ethernet), IPTABLES-routing and control interface, 
UNIONMOUNT- to get the file system with all the layers in image in it, into the container at start to took(it is like isolated file system from rest of the host). 


Why now Docker?

The Isolation Problem:

Docker gives isolation like VM's, It allows to maintain multiple versions of same application in the same host.

The Problem of environments:

Once the Vm became more handy it increased the need no of environments to test in operations, production and user device. 

Every part in this for particular environment whcih needs the different configurations 

The container image itself became a abstract or a contract between where its run and whats running inside it.

The Problem of Speed,

Taking about Business, the docker helps to execute the ideas in then SDL and express the ideas in effective way to customer.

Develop, Build, test and Deploy faster,

Container exists  because: better isolation in single os, reduced evironment variences, increasing the speed of change(SDL and Business)


Containers:

'Docker Version'---> returns the versions of client and server docker engine in their services.

it validates the connection between them.


'Docker info'---> it returns the configuration setup of the engine. Eg: No of containers , images, running, stopped


Images vs Containers:

An Image is the binaries and libraries and source code that all make up the application.

A container is a running instance of that image.
 
We can have many numbers of conatainers using same image.

Eg to run nginx container: Docker container run --publish 80:80 nginx

Step1: Downloaded the latest image 'nginx' from the docker hub.

step2: started a new conatiner from that image.

Step3: opened port 80 on the host IP.

Step4: Routes the traffic to the container IP, port80.

'Docker Container ls'---> list the running containers.
'Docker Container run' ---> starts a new container from an image.

Eg to run nginx container DETACH mode: Docker container run --publish 80:80 --detach nginx

tells the docker to run it in background.

'Docker container stop' <container ID>---> stops the containers process but does not remove it.

'Docker Container ls -a'--->List all the containers running and stopped .

Run Vs Start

'Docker conatiner run' always starts a *new* container.

'Docker container start' used to start an existing stopped one.

By Default, the names that are given by docker are a random ones(if not specified) that are genearted automatically from
an open source list of adjectives and surnames of notable hackers and scientists.
 
Eg to run nginx container in DETACH mode with specific name: Docker container run --publish 80:80 --detach --name webhost nginx
 To run a MYSQL we can use docker run -d -p 3306:3306 --name DB -e MYSQL_RANDOM_ROOT_PASSWORD=YES mysql
'Docker conatiner logs' <ID> or <name>
to list the logs of containers.

what happens when 'Docker Container run'

It looks for the image that was specified at the end of the command {eg: niginx}, looks for the image 
locally (it looks it in the image cache)if not available it will pull it from the registry.

It downloades the latest version if the version is not specified.

then it will creats a new container based on the image, it actually going to start a new layers of changes, right on top of where the image left off,

then it will customise the networking, it gives a specific Ip address thats inside a docker virtual network 

then it will open up the port that specified, if the ports are didn't mentioned using --publish then it not open any ports. Eg: 80:80 
opens the ports 80 on host & forwards to port 80 in container

then the container will start the CMD specified in the docker file.


What a container do:(to check the behavior)

'Docker container top'---> returns the list running process in specific container.

'ps aux'--> it returns the process running in linux machine.

'Docker container inspect'--> shows the metadata about the container (startup config, volumes, networking, etc)

'docker container stats'---> it shows the performance data of all containers.

Getting inside a container:

'Docker container run -it'

where, -t for allocating a pseudo -tty(simulates a real terminal, like what SSH does)
       -i interactive (keep the session open to receive terminal input)

to run a container in interactive mode:
'Docker run -it --name proxy nginx bash'

here the 'bash' is specified at the end is nothing but we are passing command or arguments telling what the container to do when it starts up.

bash shell--> if run with -it, it will give you a terminal inside the running container.
 it takes to the inside of the container as root user

Also we can run a container in interactive mode while we giving run command in it and we can do adminstrative work inside the container and 
download packages and update within the container but the resources will be mininmal. for example we can run in interactive mode on a 
ubuntu container by pulling the image and then we can install curl in it and it will work like local machine.

once we stop the conatiner it will not shows in LS and if we want start that container in interactive mode we need to use'docker container start -ai <name con>'

if we want to see the shell inside a running container that actually running something like MYSQL or NGINX we can use 'docker container exec -it <name of con>'
[Run addtional process in running container ], this helps to run additional process in an running conatainer without interrupting the primary process

Eg: while troubleshooting

Using ALPINE:

Alpine is a small security focused distribution of linux.

docker container run -it alpine bash---> it will return bash isn't in side the container 

so,this proves that we can run only things in the container that already exists in image 

In alpine the bash does not exists, instead it has sh(shell)

  
Docker Networks: 

Review: "-p " which exposes the port on your machine.

Docker Conatiner Defaults:

When a container is getting started, in background it is getting connected to a particular Docker Network(Private Virtual network).

By Default, it connects to "Bridge Network".

Then each one of those networks that are connected to actually route through a NAT firewall on Host IP , whcich actually the docker

Daemon Configuring the host Ip address on its default  interface so that your container can get out the internet or to the rest if the
network and then get back

All the containers on a virtual network can talk to each other without -p
 
Eg: if a application had an SQL server and PHP Apache container , those  two containers should be on the same network and 
they are able to talk to each other without actually opening their ports to the rest of the physical network.

And if the an another application unrelated, that was using Mongo and node.js, we could create network for that so that they could
talk with each other without using the "-p" to expose them to the network. but they couldn't actually talk to the other network
where you might have an unrelated app running.

it is like "Batteries included but removable:)"
 
Defaults work in most of the cases but easy to swap out parts to customise it.

The -p/ --publish is publishing the ports is always in HOST:CONTAINER format.

"Docker container port <container name/ID>" ----> shows the ports forwarding traffic in that container from the 
host to the container itself.

The container will not use the ip address of the host itself, by default we can use inspect to figure out, using "format" option

"--format"----> command option for formatting the output of commands using "GO templates"

to know the Ip address of the container "docker container inspect --format '{{.NetworkSettings.IPAdress}}'<container name>"(if it is windows 
we need to use double qoutes rather than single quotes in --format)

this is actual node of that json output that will get..

The output (ipaddress) will not be same as host IP.

In docker we cant make a container to listen on more than one port at the host level, only one can listen.

Containers can talk to each other inside there own virtual network unless they are connected in the same VN.

If they the containers are connected to different VNs and wants to talk to each other then they need to go via their
listening IP all they out the physical network again coming into the firewall then to ethernet interface then to the 
another VN.

Docker Networks: CLI Management of Virtual networks:

"Docker Network ls"--> Shows the list of networks (spawns a new virtual network for the container that we want to connect.)

"docker network inspect"---> to inspect a network

"docker network create --driver" ----> Create command that has an optional driver that we can specify for using built-in
and third party drivers to create a new virtual network.

"Docker network connect"----> Attach a network to container.(Dyanmically creates a NIC in a container on an existing VN)

"Docker network disconnect" ----> for detach a network from container, so that a new NIC is created on a virtual network for that
container.(Dyanmically removes a NIC in a container on an specific VN)

"Bridge" network in  docker which is a default network that bridges through NAT firewall to the phyical network that the host 
is connected to....
    "--network bridge"---> Default docker VN, which is NATed behind host IP.

"Host" network is a special network that skips the virtual networking of docker and attaches the container directly to the 
host interface.
    "--network host"---> it gains performance by skipping virtual networks but sacrifies security of container model.
it has its own pros and cons be it actually prevents the security boundaries of the containerization from protecting 
the interface of that container.

Also it can increase the perfromance of high throughput networking.

"NONE" Network of having an inteface on the computer thats not attached to anything, 

    "--network none" removes eth0 and only leaves with localhost interface in container.


A network driver created a virtual network locally with its own subnet somewhere around 172.17 and above...

   
Points of Docker Networking: Default Security

Create the apps so the FE/BE sit on same docker network.
Their Inter-communication never leaves host.
All externally exposed ports closed by default.
We must manually expose via -p, which is better default security.

Docker Networks: DNS

There is one cruial thing to all these containers and virtual networks and them taking to each other, and thats naming.
because in the world of containers constantly launching and disappering & moving & expanding & shrinking and of these 
microservices that we're seeing cropup everywhere, is that we no longer rely in IP address as the way to talk (Forget Ips)
from one thing to other. Because we can't assume from minute that IP addresses are may even going to be same, the container
might go away ot it might fail and then docker brings it up somewhere else. 

It just too dyanamic and too complicated to deal with that.

but there is solution for this and that is DNS naming.

Docker DNS: Docker daemon has a built -in DNS server that container use by default,
 The container names are equivalent of a host name for containers taking to each other.

  






 





