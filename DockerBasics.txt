Introduction to docker:

Before docker there are scenarios like code which has been developed by the Developer which is working fine for them 
but when it has been moved to the test environment the code doesn't work on the other system due to difference in the computer environments

There are two ways to overcome this: 

1. We can use a virtual machine.
2. We can use Docker.

   Criteria              Virtual Machine                                                Docker 

OS Support           Occupies a lot of memory space                      Docker container occupies less space.

Boot-up time         long boot-up time                                   short boot-up time

Performance          Running multiple virtual machines                   Containers have a better performance. 
                     leads to unstable performance                        as they are hosted in a single docker engine.

Scaling              Difficult to scale up                               Easy to scale up.

Portability          Compatibility issues while portability               Easily portable across different platforms
                     across different Platforms 

Efficiency            Low efficiency                                      High Efficiency 

Space allocation     Data Volumes cannot be shared                       Data volumes can be shared and reused among multiple containers.

Docker is a tool which is used to automate the deployment of applications in lightweight containers. 
so that applications can work efficiently in different environments

A container is a software package that consists of all the dependencies required to run an application.

so multiple containers run on the same hardware.
Containers are Maintained in isolated applications.
They are Highly productive. 
They are quick and easy to configure.

Docker working:
When the docker is installed in the host machine it is the base engine, a main component i.e., docker engine. 
that has all the different components that run the docker environment.

Docker Engine: is the base engine installed on the host machine to build and run the containers using docker components and services. 

It uses the Client-Server Architecture: Client component, which is docker CLI, REST API, Server side which is docker DAEMON.

Clients will be installed on the hardware.

There is a server which controls how the docker client is created.

Docker client and server communicate using a REST API (This can be interfaced and programmed).

Docker Client is a service which runs commands. The command is translated using REST API and is sent to the docker daemon (server).

Then, Docker Daemon Checks the client request and interacts with the OS in order to create and manage containers.

Components of Docker:

Docker Client- server: It is accessed from the terminal (PowerShell for windows & Terminal window for mac os) and a docker host runs the docker daemon and registry.

When the terminal window opens the users can build Docker Images and run docker containers by passing commands from the Docker Client to Docker Server.


Docker Image:

Docker Image is a template with instructions, which is used for creating Docker containers.
Docker Image is built using a file called docker file.
Docker Image is stored in a DockerHub or in a repository that allows other to use it.
Docker files can be created using docker commands to form a definition of image.

Docker Container:
It is a standalone, executable software package which includes applications and their dependencies.
Numerous docker containers can run on the same infrastructure and share the os with other containers.
Here, each application runs in isolation.


Docker Registry:

Docker registry is an open-source server-side service used for hosting and distributing images.
Docker also has its own default registry called Docker Hub.
Here, Images can be stored in either public or private repositories.
Pull and Push are the commands used by users in order to interact with a Docker Registry


Docker file creates a docker image using build command.
A docker image contains all the projects code.
using docker image, any user can run the code in order to create Docker containers.
Once a docker image is built its uploaded in a registry or a docker hub
From the dockerhub, users can get the docker image and build new containers.


Advantages of Docker: Rapid Deployment
                      Portability
                      Better Efficiency
                      Faster Configuration using YAML.
                      Highly Scalability
                      Security


Docker engine or docker is a client server application that builds and executes containers using docker components.
REST API is a primary mode of communication between docker client and docker daemon.
docker toolbox is used for older versions windows and Mac systems with the following features:
Docker Engine, Docker Machine, Docker Compose, Kitematic.

Components of Docker:

Docker Client: Docker client consists of the CLI command which is used to issue commands to the docker daemon.
Docker Client uses RESTAPI to issue commands to docker Daemon through scripting or direct CLI commands.
ForEg: if we use docker pull command, the client sends this command to daemon, which performs the operation.
by interacting with other components (image, container, Registry)
Docker Daemon is a service which interacts with the operating system and performs all kinds of services.

The Docker Daemon listens for the REST API Request and Performs the operation.

A command dockerd is used to start a Docker Daemon.

Docker Host runs the Docker Daemon and Registry.


Docker IMAGE:

A Docker Image is a Template of instructions which is used to Create Containers. It is written in a format called YAML.

Docker image is built using a file called Docker File.

It is comprised of multiple Layers.

By default, Docker image starts with a base layer.

Here, each layer depends on the layer below it.

Image layers are created by executing each command in the Docker file and are in the read only format.



Whenever a user creates a container, a new layer is formed on top of the image layers called container layer.

Every container has a separate (R/W) container layer and any modification in a container 
is reflected upon the container layer alone (we can be able to create a own read/write instructions within a container).


When a container is deleted, the top layer also gets deleted.

What should be done when there is a change in the image layer?

Users can add a new layer to the base image.

But the users cannot modify any of the existing image layers.

The actual main image cannot be modified. but we can modify it locally after copying it.

DID YOU KNOW:

Base Layers are in the read only format.

The layers can be combined in a union file system to create a single image.

The Union File system saves memory space by avoiding duplicating the files.

This allows a file system to appear as writable (but without modifying the file) which is known as copy-on-write.



Docker uses a copy-on-write strategy with both docker images and docker containers themselves.

CoW is a strategy to share and copy files for better efficiency.

This strategy makes the docker as efficient by reducing the usage of disk space and increasing the performance of container.


Docker Registry:

Docker Registry is a service to host and distribute docker images among users.

A repository is a collection of docker images.

In Registry, a user can distinguish between docker images with their tag names.
[A tag name is alphanumeric identifier attached to an image]


Docker has its own cloud-based registry called Dockerhub where users store and distribute container images.

Docker registry has public and private repositories.

In Registry, PUSH and PULL commands are used to interact with the docker images.

PULL Command- It pulls(retrieves) a docker image from the Docker Registry.

PUSH Command- It pushes(stores) a docker image in a Docker Registry.

DID YOU KNOW: 

In Docker Registry, deleting a repository is not a reversible action.

Docker Container: 

It is an executable package of application and its dependencies together.

Since it's Light weight, it can be easily deployed and executed on other computer environments regardless of 
their host OS/configurations.

Docker containers run applications in isolation and also share the OS kernel with other containers.

Data volumes can be shared and reused among multiple containers.

It is built using Docker images.

Docker RUN command builds a container.



DOCKER COMPOSE:

It is used for running multiple containers as a single service.

Here, each container runs in isolation but interacts with each other.

All Docker compose files are YAML files.

FOR EG: if we have an application that requires Apache server and MY SQL database we could. 
create one Docker Compose file which can run both container as a service without the need to start each one separately.


DOCKER SWARM: 

Docker Swarm is a service for containers which allows IT administrators and developers to create.  
and manage a cluster of swarm nodes within the Docker Platform.

A swarm node is an individual docker engine participating in the swarm.

Each node of docker swarm is a docker daemon and all the docker daemons interact using docker API.

A Swarm consists of two types of nodes: Manager node and worker node.

Manager Node maintains the cluster management Tasks. 

Worker nodes receive and executes tasks from manager node.

Docker basic commands,

yum install Docker---> install Docker on your system.

Sytemctl start Docker---> start the docker daemon.

Docker rmi <Image ID>---> to remove a docker image.

Docker pull <image_name>---> command to download an image.

Docker run <image_id>---> command to run an image.

Docker pull <image-name: tag>---> command to pull a specific Docker image from a docker hub.

Docker build -t [image-name]: tag

Docker stop <Container_ID>---> Command to shut down a running container.

Docker exec its container_ID bash--> command to access a running container.

Architecture of Docker Container:

DID YOU KNOW:

When a container is created, a new layer is formed on the top of the docker image layers called Container layer.

Each Container has a separate (R/W) container layer and any changes made in a Docker Container is reflected. 
upon the particular Container layers.

In case a container is deleted, the container layer also gets deleted.

Docker Container Commands,

Docker Container commit- Command to create a new docker image from the changes made in container.

Docker Container cp- command to copy files between the local filesystem and a docker container.

Docker Container prune- Command to remove all stopped containers.

Docker Container kill- command to terminate one or more running containers.

Docker Container exec- Command to run a new command in a running container.

Docker Container ls- Command to list Docker containers.

Docker Container rm- Command to remove one or more containers.

Docker Container restart- command to restart one or more containers.

 
DOCKER SWARM:

How do we make Docker work across multiple nodes so that they can share containers among each other?

Ans: Docker SWARM.

Docker swarm is an environment where we can share multiple docker images running in the same Host OS, 
With this we can be able to run Docker Containers with Different solutions.

Docker Swarm allows us to create and schedule multiple Docker Nodes (two or more nodes), 
We can also have a large number of docker nodes in a single swarm.

Docker Swarm is a service which allows users to create and manage a cluster of Docker Nodes and schedule Containers.

In Docker Swarm, each node is a docker daemon, 
and the daemon can be able to interact with the Docker API and it has the full benefits of Docker Daemon

Each node of a Docker Swarm is a Docker daemon, and all Docker Daemons interact using the Docker API.

Another Advantages is Each Docker container within the Swarm can be deployed and managed as a node in that entire clustered environment.

Docker Swarm provides high availability of resources in case of any failure in containers.

Docker Swarm can Reschedule containers on node failures (with Docker swarm on fault tolerance)

Swarm node has a backup folder, in case the main node fails, it can be used to restore the data onto a new Swarm.

Features of Docker Swarm:

It is fully Decentralized, very easy to access and manage the environment.

Communication between the Manager and Client Node is Highly Secured.

Auto Load Balancing, which can be utilized based on the structure of the Swarm Environment.

High Scalability, Due to the Auto Balancing it achieves this too.

Roll Back a task, we can ably bring back the Previous same environment.

In swarm, Containers are launched using services i.e., the Rest Service APIs are used.

A Service is a group of containers of the same image.

This Services enables to scale the application on-demand.

Before the deployment of Docker Swarm, the environment should have at least one node Deployed.

Types of Nodes: Manager Node & Worker Node

MANAGER NODE: Manager Node maintains the cluster management tasks.

WORKER NODE: It receives and Executes tasks from the Manager Node.


Architecture of Docker Swarm:


		 MANAGER NODE
										
								
								
  WORKER NODE1    WORKERNODE2      WORKERNODE3
						
						
Manager Node knows the status of all the worker nodes in a cluster.

Worker nodes accepts tasks sent from manager.

Every worker node has an agent, which reports on the state of the node's tasks.
to the manager so, the Manager node has the full control of the environment. This way,
the manager node can maintain the desired state of the cluster.

The Worker nodes communicate with the manager node using API over HTTP.

In Docker Swarm, Services can be deployed and accessed by any nodes of same cluster.

While creating the service, a user has to specify which container image to use.

The worker nodes communicate with the manager node using the RESTAPI over HTTP.

In Docker, Once the services are deployed and accessed by any node of same cluster.

While creating a service, the user has to specify which container image to use.

Here a service is either global or replicated.

A global service will run on every swarm node.

In replicated service, the manager node distributes tasks to worker nodes.

Diff btw Services and Tasks: 
A Services is a description of a task or the state, where as a task does the work.

Docker enables a user to create services, which can start tasks.

When a task is assigned to a node the same tasks cannot be assigned to another node.

DID YOU KNOW: It is possible to have multiple manager nodes on Swarm, but there?
will be only one primary manager node, which gets elected by the other manager nodes.

Recap
  
       Manager Node                              Worker Node

         API                                   Checks for the tasks
{based on the CLI Command                 {Connects to the manager node
a service is created}                      checks for new tasks}

        Orchestration                          Executes the Tasks
{Once we connect with the API             {Assigned tasks will be executed}
we can be able to create for each.  
service}
     
        Tasks Allocation
{Allocates the tasks via IP address.
(Of worker node tasks)}
    
        Dispatcher and Scheduler
{Assigns and instructs worker nodes.
to run a task}

           

DOCKER COMPOSE

With Docker Compose, it is possible to run more than one container in a single service.

Here, Containers run in isolation but can be able to interact with each other.

In Docker composer, a user can start all the services using a single command.

Benefits of Docker Compose:

Single Host Deployment.
Quick and Easy configuration.
High productivity.
Security.









